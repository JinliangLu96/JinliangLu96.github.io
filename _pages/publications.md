---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

{% if site.author.googlescholar %}
  <div class="wordwrap">You can also find my articles on <a href="{{site.author.googlescholar}}">my Google Scholar profile</a>.</div>
{% endif %}

{% include base_path %}

* **Jinliang Lu** and Jiajun Zhang. Improving Unsupervised Neural Machine Translation via Training Data Self-Correction. In *Proceedings of 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)*, Accepted.
* Yangyifan Xu*, **Jinliang Lu** * and Jiajun Zhang. Bridging the Gap between Different Vocabularies for LLM Ensemble. In *Proceedings of 2024 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT 2024)*. Accepted
* **Jinliang Lu**, Yu Lu and Jiajun Zhang. Take a Closer Look at Multilinguality! Improve Multilingual Pre-Training Using Monolingual Corpora Only. In *Findings of the Association for Computational Linguistics: EMNLP 2023*, Singapore, December 6-10, 2023, pp.2891â€“2907.
* **Jinliang Lu** and Jiajun Zhang. Towards Unified Multi-Domain Machine Translation with Mixture of Domain Experts. *IEEE/ACM Transactions on Audio, Speech, and Language Processing (TASLP)*, 2023, 31: 3488-3498.
* **Jinliang Lu**, Feihu Jin and Jiajun Zhang.Adapter Tuning With Task-Aware Attention Mechanism. In *Proceedings of 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2023)*, Rhodes Island, Greece, June 2-10, 2023, pp.1-5.
* Feihu Jin, **Jinliang Lu** and Jiajun Zhang. Unified Prompt Learning Makes Pre-Trained Language Models Better Few-shot Learners. In *Proceedings of 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2023)*, Rhodes Island, Greece, June 2-10, 2023, pp.1-5.
* 
